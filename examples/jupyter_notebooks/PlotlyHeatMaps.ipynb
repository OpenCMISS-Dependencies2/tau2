{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice, cycle\n",
    "from tau_profile_parser import TauProfileParser\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly as py\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn on offline mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#py.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotly Bar Plot Examples\n",
    "========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates using the TauProfileParser to parse TAU profile.x.y.z files and using Plotly to generate ParaProf-style bar plots from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TAU Profile Parser\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we call `TauProfileParser.parse` on the path to a directory containing TAU profile files. \n",
    "\n",
    "Note that the parser does not currently have any native support for MULTI_ directories, so if you have those\n",
    "you'll have to call parse multiple times and then, if you wish, merge the resulting dataframes. This functionality should be added to the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mutiProfiles = 'path/to/files'\n",
    "lulesh_data= TauProfileParser.parse(path_to_multiProfiles,MULTI=True)\n",
    "lulesh_data.interval_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flat = lulesh_data.interval_data()\n",
    "data_flat.columns = data_flat.columns.to_flat_index()\n",
    "data_flat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns an object that provides access to the metric name, metadata, and the interval and atomic/userevent data.\n",
    "\n",
    "The `metric` attribute contains the metric that values in this profile represent. (This representation will need to change when multi-metric data can be read in directly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lulesh_data.metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `metadata` attribute contains a Python dictionary of the metadata recorded in the profile.0.0.0 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lulesh_data.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `indices` attribute contains the (node, context, thread) tuples that are present in this profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeatMap\n",
    "\n",
    "A heat map of the `col_name` values amongs the `TOP_N` common timers between all of the threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node, context = 0, 0\n",
    "col_name = ('Exclusive','TIME')\n",
    "TOP_N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_func_data(data):\n",
    "    \"\"\"\n",
    "    Everything but the TAU_CALLPATH group\n",
    "    \n",
    "    param:\n",
    "        data: DataFrame\n",
    "    \"\"\"\n",
    "    data = data.loc[~data[\"Group\",\"\"].str.contains(\"TAU_CALLPATH\")]\n",
    "    return data\n",
    "    \n",
    "def create_callpath_data(data):\n",
    "    \"\"\"\n",
    "    Only the TAU_CALLPATH group\n",
    "    \n",
    "    param:\n",
    "        data: DataFrame\n",
    "    \"\"\"\n",
    "    data = data.loc[data[\"Group\",\"\"].str.contains(\"TAU_CALLPATH\")]\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_threads(raw_data):\n",
    "    \"\"\"\n",
    "    Finds number of threads found in raw_data\n",
    "    \n",
    "    param:\n",
    "        raw_data: DataFrame (interval_data())\n",
    "    \"\"\"\n",
    "    d = raw_data.loc[0, 0]\n",
    "    threads = set([i[0] for i in d.index])\n",
    "    return len(threads)\n",
    "\n",
    "def trim_data(data, num_threads, top_n, col_name):\n",
    "    \"\"\"\n",
    "    creates and returns a dataframe containing the `top_n` `col_name` column of the `data` DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df = None\n",
    "    cntr = 0\n",
    "    first = True\n",
    "    for thread in range(num_threads):        \n",
    "        tmp = data.loc[node, context, thread][[col_name]] \n",
    "        tmp = tmp.sort_values(by=[col_name], ascending=False)  \n",
    "        \n",
    "        if first: \n",
    "            df = tmp\n",
    "        else: \n",
    "            df = df.merge(tmp, how='inner', on=['Timer'], suffixes=(f\"_{str(cntr)}\", f\"_{str(cntr + 1)}\"))\n",
    "            cntr += 1\n",
    "        first = False\n",
    "    print(tmp)\n",
    "    truncated = df[:top_n]\n",
    "    truncated = truncated.fillna(\"\")\n",
    "    return truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = find_num_threads(data_flat)\n",
    "num_threads\n",
    "\n",
    "callpaths = create_callpath_data(data_flat)\n",
    "callpaths = trim_data(callpaths, num_threads, TOP_N, col_name)\n",
    "callpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_func_data(data_flat)\n",
    "data = trim_data(data, num_threads, TOP_N, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function_labels(data):\n",
    "    \"\"\"Creats a list of labels to be desplayed on the y axis of heatmap\"\"\"\n",
    "    functions_labels = [f for f in data.index]\n",
    "    return functions_labels\n",
    "\n",
    "def trim_a_single_call(single_call):\n",
    "    \"\"\"Strips and gets rid of the arguments of the timers signature\"\"\"\n",
    "    func_name, location, timer_type = TauProfileParser.extract_from_timer_name(single_call)\n",
    "    func_name = func_name.strip() if func_name is not None else \"\"\n",
    "    timer_type = f\"[{timer_type.strip()}]\" if timer_type is not None else \"\"\n",
    "    single_call = \" \".join([timer_type, func_name])\n",
    "    single_call = single_call[:single_call.find(\"(\")] if single_call.find(\"(\") != -1 else single_call\n",
    "    return single_call\n",
    "    \n",
    "def trim_single_call_data(single_calls):\n",
    "    functions_labels = [trim_a_single_call(f) for f in single_calls]\n",
    "    return functions_labels\n",
    "\n",
    "def trim_call_path_data(call_paths):\n",
    "    \"\"\"A callpath contains individual calls separated by `=>`, this function trims each individual call\"\"\"\n",
    "    functions_labels = []\n",
    "    for f in call_paths:\n",
    "        f = f.split(\" => \")\n",
    "        f = [trim_a_single_call(i) for i in f]\n",
    "        label = \" => \".join(f)\n",
    "        functions_labels.append(label)\n",
    "    return functions_labels\n",
    "\n",
    "def create_thread_labels(num_threads):\n",
    "    \"\"\"Creates thread labels that are the x-axis labels of our heatmap\"\"\"\n",
    "    return [f\"thrd_{str(t)}\" for t in range(num_threads)]\n",
    "\n",
    "def create_heat_map_data(data): \n",
    "    \"\"\"Creates a 2d list which is the `heat` data needed for the heat map\"\"\"\n",
    "    heat_map_data = []\n",
    "    for r in data.iterrows():\n",
    "        row = [i for i in r[1]]\n",
    "        heat_map_data.append(row)\n",
    "    return heat_map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "def show_heat_map(heat_map_data, call_labels, thread_labels):\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "                    z=heat_map_data,\n",
    "                    x=thread_labels,\n",
    "                    y=call_labels\n",
    "                ))\n",
    "    fig.show()\n",
    "    \n",
    "def create_labels(data, num_threads):\n",
    "    \"\"\"creates x-axis and y-axis labels\"\"\"\n",
    "    thread_labels = create_thread_labels(num_threads)\n",
    "    function_labels = create_function_labels(data)\n",
    "    return thread_labels, function_labels\n",
    "\n",
    "def show_heat_map_single_call(single_call_data, num_threads):\n",
    "    \"\"\"For single calls\"\"\"\n",
    "    thread_labels ,function_labels = create_labels(single_call_data, num_threads)\n",
    "    function_labels = trim_single_call_data(function_labels)\n",
    "    heat_map_data = create_heat_map_data(single_call_data)\n",
    "    show_heat_map(heat_map_data, function_labels, thread_labels)\n",
    "    \n",
    "def show_heat_map_call_path(call_path_data, num_threads):\n",
    "    \"\"\"For call_path\"\"\"\n",
    "    thread_labels ,function_labels = create_labels(call_path_data, num_threads)\n",
    "    function_labels = trim_call_path_data(function_labels)\n",
    "    heat_map_data = create_heat_map_data(call_path_data)\n",
    "    show_heat_map(heat_map_data, function_labels, thread_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_heat_map_single_call(data, num_threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_heat_map_call_path(callpaths, num_threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(callpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
