{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tau_profile_parser import TauProfileParser\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions: \n",
    "Drag this notebook into the main folder that contains the TauProfile parent folders.  \n",
    "  \n",
    "Example:  \n",
    "/documents/experimentName/folder1/profile.0.0.0   \n",
    "/documents/experimentName/folder1/profile.1.0.0  \n",
    "/documents/experimentName/ThisNotebook  \n",
    "  \n",
    "  \n",
    "#### UI  \n",
    "At minimum, the user need only change a few key variables listed throughout the notebook.  \n",
    "The notebook will read the files from the local folder.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_data = False\n",
    "processes_per_node = 42 # Dependent on machine\n",
    "sample_on = True\n",
    "# print(os.getcwd()) # Verify working directory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ExampleData = os.getcwd()\n",
    "directory_contents = os.listdir(path_to_ExampleData)\n",
    "folders = [item for item in directory_contents if os.path.isdir(item) and item[0] != '.']\n",
    "\n",
    "# sort by number of ranks\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Logic\n",
    "# if all false, then no multi files, but if one is True then there is a MULTI file\n",
    "\n",
    "multi_bool = False\n",
    "for fold in folders:\n",
    "    subdirs_names = os.listdir(path_to_ExampleData+'/'+fold)\n",
    "    subfolders = [item for item in directory_contents if os.path.isdir(item) and item[0] != '.']\n",
    "    if any([False if 'MULTI' not in fold else True for subfold in subfolders]):\n",
    "        multi_bool = True\n",
    "        break\n",
    "    \n",
    "# print(multi_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TauProfObjects = [TauProfileParser.parse(path_to_ExampleData+'/'+fold, MULTI=multi_bool) for fold in folders]\n",
    "\n",
    "# print(TauProfObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see experiment details, metadata will print out information\n",
    "\n",
    "# TauProfObjects[1].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataframes from a tau profile object\n",
    "\n",
    "Using the Atomic data from counters. The TauProfileParser obeject uses .atomic_data() to return a dataframe of the counters.\n",
    "For timer data, .interval_data() is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counter_data:\n",
    "    Dataframes1 = [obj.atomic_data()   for obj in TauProfObjects]\n",
    "else:\n",
    "    Dataframes1 = [obj.interval_data() for obj in TauProfObjects]\n",
    "\n",
    "print(type(Dataframes1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timers = [timer for timer in set(Dataframes1[0].index.get_level_values(\"Timer\")) if 'TAU application' not in timer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in enumerate(timers):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of timers we want to visualize\n",
    "\n",
    "selected_timers = [\"*** custom:Grid_updateRefinement:amrex_regrid\",\n",
    "\"MPI_Allgather()\",'*** custom:RiemannState']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [(int(int(len(set(frame.index.get_level_values('Node'))))/processes_per_node),frame) for frame in Dataframes1 ]\n",
    "dataframes = sorted(dataframes, key=lambda x: x[0])\n",
    "dataframes = list(map(lambda x: (str(x[0]),x[1]), dataframes))\n",
    "print(dataframes[0][0])\n",
    "dataframes[0][1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a df with columns of all the papi_ counters, this df will be only the mean values\n",
    "\n",
    "Read out of the correlated timers is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(df1, noutliers=5):\n",
    "    # returns a smaller dataframe using pandas.sample()\n",
    "    \n",
    "    df = df1.copy()\n",
    "    new_df = pd.DataFrame()\n",
    "    ####### Uncomment below to include Max and min outliers ############\n",
    "\n",
    "    #     for _ in range(5): # add mins\n",
    "    #         maxes = df.idxmax()\n",
    "    #         for m in maxes:\n",
    "    #             new_df = new_df.append(df.loc[m].T)\n",
    "    #             df.drop([m])\n",
    "    #         mins = df.idxmin()\n",
    "    #         for n in mins:\n",
    "    #             new_df = new_df.append(df.loc[n].T)\n",
    "    #             df.drop([n])\n",
    "    new_df = new_df.append(df.sample(frac=.25, random_state=1))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetric(dfs, metric, timers=None, sample_on=sample_on):\n",
    "    # dfs is list of tuples [(#nodes, dataframe), (n,df)...]\n",
    "    et_df = []\n",
    "    for df in dfs:\n",
    "        tmp = pd.DataFrame()\n",
    "        nodemax = df[1].index.get_level_values(0).max() + 1\n",
    "        for node in range(nodemax):\n",
    "            tmp = tmp.append(df[1].loc[(node,0,0),metric].T)\n",
    "        tmp.reset_index(drop=True, inplace=True)\n",
    "        et_df.append(tmp)\n",
    "        \n",
    "    sums = et_df[0].sum()\n",
    "    sums.sort_values(ascending=False, inplace=True)\n",
    "    # Drop .TAU application\n",
    "    sums.drop(labels='.TAU application', inplace=True)\n",
    "    \n",
    "    # call paths\n",
    "    for column in sums.index:\n",
    "        if '.TAU application' not in column:\n",
    "                continue\n",
    "        sums.drop(column, inplace=True)\n",
    "        \n",
    "    # drop the MPI TIMERS\n",
    "    #for timer in orig_sums.index:\n",
    "    #    if 'MPI' in timer:\n",
    "    #         print(timer)\n",
    "    #        orig_sums.drop(labels=timer, inplace=True)\n",
    "    \n",
    "    # timers\n",
    "    sel_timers = timers\n",
    "    if not timers:\n",
    "        top = sums.head(4)\n",
    "        sel_timers = [timer for timer in top.index]\n",
    "    if sample_on: \n",
    "        et_df = [samples(df) for df in et_df]\n",
    "        \n",
    "    return et_df,sel_timers\n",
    "\n",
    "def doHistograms(non_normal_df, top_timers, m1):\n",
    "    for tt in top_timers:\n",
    "        hfig = px.histogram(non_normal_df, x=tt, color=\"Method\", marginal=\"box\")\n",
    "        title = m1\n",
    "        hfig.update_layout(height=400, width=600, title=title)\n",
    "        hfig.show()\n",
    "\n",
    "def doSplom(title, df, dims):\n",
    "    fig = px.scatter_matrix(df, dimensions=dims, color=\"Method\", hover_data=['Node'])\n",
    "    # if saving, use width=1500, else use width=1000\n",
    "    fig.update_layout(height=1500, width=1000, title=title)\n",
    "    #fig.write_html(\"/path/to/save/splom_orig_nocall_noMPI_non_norm.html\") # uncomment to save to files for easier viewing and sharing\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for visualization\n",
    "metric = 'Inclusive'\n",
    "timers = selected_timers\n",
    "sample_on = True        # if you would like full data, make False. Uses lots of RAM and slows browser down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_df,splom_timers = getMetric(dataframes, metric, timers, sample_on)\n",
    "for df in et_df:\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "et_df[0].index\n",
    "### add the method to the orig_time data frames to plot non-normalized dataframes\n",
    "subdirs = [folder[0] for folder in dataframes]\n",
    "print(subdirs)\n",
    "for df,sd in zip(et_df,subdirs):\n",
    "    df['Node'] = df.index\n",
    "    df['Method'] = sd\n",
    "\n",
    "non_normal_df = pd.concat(et_df)\n",
    "doHistograms(non_normal_df, splom_timers, metric)\n",
    "\n",
    "# creating a title using selected timers.\n",
    "if not timers:\n",
    "    title = 'Top 6 Timers on Original Run sorted by ' + metric # change title!!\n",
    "else:\n",
    "    title = 'Sorted Timers: '\n",
    "    for timer in timers:\n",
    "        title += timer +',\\n '\n",
    "    title+= 'by ' + metric\n",
    "\n",
    "doSplom(title, non_normal_df, splom_timers)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
